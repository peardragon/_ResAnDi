{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils._resnet import resnet18_8\n",
    "from utils._preprocessing import _preprocessing\n",
    "from captum.attr import LayerGradCam\n",
    "from captum.attr import LayerAttribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def _save_dataset_gradcam(dataset_path, tag=\"\",\n",
    "                         shuffle=False, device='cuda'):\n",
    "\n",
    "    save_dir = f\"./Grad-CAM/GradCAM-Residual-{tag}.npy\"\n",
    "    if os.path.exists(save_dir):\n",
    "        return\n",
    "    dataset = np.load(dataset_path, allow_pickle=True)\n",
    "    model_path = f\"./model_backups/resnet18_8_b64_lr0.0001/checkpoint.pt\"\n",
    "\n",
    "    model = resnet18_8()\n",
    "    model.load_state_dict(torch.load(model_path), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = _preprocessing(dataset, batch_size=256, shuffle=shuffle)\n",
    "\n",
    "    model.to(device)\n",
    "    attributions = []\n",
    "    sampled_dim = 1000\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for dataset in tqdm(dataloader):\n",
    "            (X,y) = dataset\n",
    "            inputs = X.to(device)\n",
    "            target = y.to(device)\n",
    "\n",
    "            gradcam = LayerGradCam(model, model.layer4)\n",
    "            attribution = gradcam.attribute(inputs=inputs, target=target)\n",
    "            attribution = torch.squeeze(attribution, -2)\n",
    "            attribution = LayerAttribution.interpolate(attribution, sampled_dim, interpolate_mode=\"nearest\")\n",
    "            attributions.extend(torch.squeeze(attribution).tolist())\n",
    "\n",
    "    np.save(save_dir, np.array(attributions))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Index : 0\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "i = 0\n",
    "print(\"Current Index :\", i)\n",
    "_ = _save_dataset_gradcam(f\"./dataset/test/{i}.npy\", tag=f\"test_{i}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for un-interpolate version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def _save_dataset_gradcam_raw(dataset_path, tag=\"\",\n",
    "                          shuffle=False, device='cuda'):\n",
    "\n",
    "    save_dir = f\"./Grad-CAM/GradCAM-raw-{tag}.npy\"\n",
    "    if os.path.exists(save_dir):\n",
    "        return\n",
    "    dataset = np.load(dataset_path, allow_pickle=True)\n",
    "    model_path = f\"./model_backups/resnet18_8_b64_lr0.0001/checkpoint.pt\"\n",
    "\n",
    "    model = resnet18_8()\n",
    "    model.load_state_dict(torch.load(model_path), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = _preprocessing(dataset, batch_size=256, shuffle=shuffle)\n",
    "\n",
    "    model.to(device)\n",
    "    attributions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for dataset in tqdm(dataloader):\n",
    "            (X,y) = dataset\n",
    "            inputs = X.to(device)\n",
    "            target = y.to(device)\n",
    "            gradcam = LayerGradCam(model, model.layer4)\n",
    "            attribution = gradcam.attribute(inputs=inputs, target=target)\n",
    "            attribution = torch.squeeze(attribution, -2)\n",
    "            attributions.extend(torch.squeeze(attribution).tolist())\n",
    "\n",
    "    np.save(save_dir, np.array(attributions))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Index : 0\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "i = 0\n",
    "print(\"Current Index :\", i)\n",
    "_ = _save_dataset_gradcam_raw(f\"./dataset/test/{i}.npy\",tag=f\"test_{i}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "andi",
   "language": "python",
   "display_name": "andi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
